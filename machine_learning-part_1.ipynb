{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08f78e6b",
   "metadata": {},
   "source": [
    "# Machine Learning - Part 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3687234",
   "metadata": {},
   "source": [
    "Herein we will be introducing and discussing some machine learning models at a high level to get first time and beginner biomedical informaticians a taste for some of the problems machine learning can help solve.\n",
    "\n",
    "As this is a brief survey course on machine learning, we will not dive too deep into the theory of these models, nor will we be able to cover every type of model. At the end of this notebook I have provided a list of references and resources that biomedical informaticians, beginner, novice, and experts alike, may find useful and insightful.\n",
    "\n",
    "<p style=\"text-align: center;\">\n",
    "  <img width=\"800px\" src=\"img/extended_ml_cheat_sheet.jpeg\"/>\n",
    "    <em><small>Image taken from <a href=\"https://medium.com/@chris_bour/an-extended-version-of-the-scikit-learn-cheat-sheet-5f46efc6cbb\">An Extended Version Of The Scikit-Learn Cheat Sheet</a></small></em>\n",
    "</p>\n",
    "\n",
    "**<font color='red'>Disclaimer</font>:** I will not be doing any data cleaning (per se) or data manipulation. This is a very large topic of its own that I will not have time to cover. However, understanding the dataset with which you are working, ensuring it is clean, workable data, and formulating hypotheses you wish to test with your data are all ***VERY*** important aspects to consider before diving into machine or deep learning models with your data. **The above figure, and corresponding article, depict this point excellently.**\n",
    "\n",
    "*I aim to provide rudimentary information about machine learning that will help you start to understand different models and when to use them. I hope to garner excitement about this field so that you go and learn more about machine learning and how to apply it to your own unique biomedical informatics problems!*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c3800f",
   "metadata": {},
   "source": [
    "## Machine learning paradigms\n",
    "\n",
    "There are many different types of models in machine learning and choosing the best one is dependent on:\n",
    "1. The problem you aim to solve\n",
    "2. The data you have\n",
    "\n",
    "In some instances multiple models may work well for you, in which case you will have to consider other aspects of the model, such as:\n",
    "* interpretability\n",
    "* memory cost\n",
    "* number of samples\n",
    "* dimensionality\n",
    "* and so on...\n",
    "\n",
    "Though these considerations may help you narrow down your choices, choosing the *best* remains a difficult task. I will provide some general information about different types of machine learning models while keeping some of the above aspects in mind.\n",
    "\n",
    "Below is a figure that shows a very well defined hierarchy of different ML models that one can consider. The upper level of this hierarchy gives 3 main learning paradigms: **supervised**, **unsupervised**, and **reinforcement**. I will discuss all 3 of these as well as a fourth, called **semi-supervised**.\n",
    "\n",
    "<img width=\"500px\" src=\"img/ml_hierarchy.png\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ac4ff8",
   "metadata": {},
   "source": [
    "### Supervised learning\n",
    "\n",
    "Samples of input-output pairs (labelled outcomes). Problems include:\n",
    "\n",
    "**Classification** - predict the binary (or class) label for an unlabeled sample. Examples: logistic regression, SVM\n",
    "\n",
    "**Regression** - predict a real-valued label for an unlabeled sample. Examples: linear regression \n",
    "\n",
    "<img width=\"400px\" src=\"img/class_v_reg.png\"/>\n",
    "\n",
    "In classification models, the boundary separating the examples of different classes is called the *decision boundary*. For regression models, the line that best fits the data is the *regression line*. \n",
    "\n",
    "References:\n",
    "- https://en.wikipedia.org/wiki/Supervised_learning\n",
    "- https://scikit-learn.org/stable/supervised_learning.html\n",
    "\n",
    "*Today we will be focused on implementing decision trees, which are considered supervised classification models. Therefore, this machine learning paradigm type will be our main focus for this notebook.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd6849d",
   "metadata": {},
   "source": [
    "### Unsupervised learning\n",
    "\n",
    "Draw inferences and patterns from input data without labelled output data. Problems include: \n",
    "\n",
    "**Clustering** - e.g., k-means\n",
    "<p style=\"text-align: center;\">\n",
    "  <img width=\"600px\" src=\"img/clustering.png\"/>\n",
    "  <em><small>Image taken from <a href=\"https://www.linkedin.com/pulse/what-clustering-machine-learning-avishek-patra-ap/\">What is Clustering in Machine Learning</a></small></em>\n",
    "</p>\n",
    "\n",
    "**Dimensionality Reduction** - e.g., PCA\n",
    "<p style=\"text-align: center;\">\n",
    "  <img width=\"400px\" src=\"img/pca.jpg\"/>\n",
    "  <em><small>Image taken from <a href=\"https://www.lancaster.ac.uk/stor-i-student-sites/ziyang-yang/2021/01/06/dimensionality-reduction-pca/\">Dimensionality Reduction – PCA</a></small></em>\n",
    "</p>\n",
    "\n",
    "Additional references:\n",
    "- https://en.wikipedia.org/wiki/Unsupervised_learning\n",
    "- https://scikit-learn.org/stable/unsupervised_learning.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79509d8e",
   "metadata": {},
   "source": [
    "### Semi-supervised learning\n",
    "\n",
    "Supervised learning tasks and techniques that also make use of unlabeled data for training.\n",
    "\n",
    "<p style=\"text-align: center;\">\n",
    "  <img width=\"800px\" src=\"img/semi_supervised_learning.png\"/>\n",
    "  <em><small>Image taken from <a href=\"https://teksands.ai/blog/semi-supervised-learning\">Introduction to Semi-Supervised Learning</a></small></em>\n",
    "</p>\n",
    "\n",
    "References:\n",
    "- https://en.wikipedia.org/wiki/Semi-supervised_learning\n",
    "- https://scikit-learn.org/stable/modules/classes.html#module-sklearn.semi_supervised"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03482a4",
   "metadata": {},
   "source": [
    "### Reinforcement learning\n",
    "\n",
    "Consists of an environment and agent both with defined states. The agent takes an action in the environment from a set of defined actions (policy). A reward is calculated for the agent in the new state which is fed back to the agent. The \"goal\" is to optimize the probability of each action such that the cumulative reward over all actions is maximized.\n",
    "\n",
    "<p style=\"text-align: center;\">\n",
    "  <img width=\"800px\" src=\"img/reinforcement_learning.png\"/>\n",
    "  <em>Image was taken from <a href=\"https://www.google.com/url?sa=i&url=https%3A%2F%2Ftowardsdatascience.com%2Freinforcement-learning-fda8ff535bb6&psig=AOvVaw2bLEQpIIG1N7yCn0ySxjoL&ust=1720720437169000&source=images&cd=vfe&opi=89978449&ved=0CBEQjRxqFwoTCKi9jKeFnYcDFQAAAAAdAAAAABAJ\">Reinforcement Learning: A Review of the Historic, Modern, and Future Applications of this Special Form of Machine Learning</a></em>\n",
    "</p>\n",
    "\n",
    "Additional references:\n",
    "- https://en.wikipedia.org/wiki/Reinforcement_learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8312b57",
   "metadata": {},
   "source": [
    "## Decision Trees\n",
    "\n",
    "<p style=\"text-align: center;\">\n",
    "  <img width=\"300px\" src=\"img/decision_tree-example.jpeg\" style=\"border:5px solid;\"> \n",
    "</p>\n",
    "\n",
    "Decision trees can be used for both classification and regression.  They are similar to if/then statements.\n",
    "\n",
    "* Tree depth: how many questions do we ask until we reach our decision? (denoted by its longest route)\n",
    "* Root node: first decision\n",
    "* Decision node: subsequent splits following the root node\n",
    "* Sub tree: smaller tree within the larger parent tree\n",
    "* Leaf node: final node of the tree\n",
    "\n",
    "<p style=\"text-align: center;\">\n",
    "  <img width=\"800px\" src=\"img/decision_tree-example2.png\">\n",
    "  <em><small>Image taken from <a href=\"https://medium.com/@shrutimisra/interpretable-ai-decision-trees-f9698e94ef9b\">Interpretable AI: Decision Trees</a></small></em>\n",
    "</p>\n",
    "      \n",
    "Advantages: \n",
    "* easy to interpret\n",
    "* can use both qualitative and quantitative predictors and responses\n",
    "* reproducible in clinical workflow\n",
    "* fast and perform well on large datasets\n",
    "\n",
    "Disadvantages:\n",
    "* need an optimal choice at each node; at each step, the algorithm chooses the best result. Choosing the best result at a given step does not ensure an optimal decision when you make it to the leaf node\n",
    "* prone to over-fitting, especially with deep trees (fix: can set a max depth--this limits variance, but at the expense of bias!)\n",
    "\n",
    "Here are some links with more information about decision trees:\n",
    "* https://www.datacamp.com/community/tutorials/decision-tree-classification-python\n",
    "* http://dataaspirant.com/2017/02/01/decision-tree-algorithm-python-with-scikit-learn/\n",
    "* https://towardsdatascience.com/how-to-visualize-a-decision-tree-from-a-random-forest-in-python-using-scikit-learn-38ad2d75f21c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc3a1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.legend_handler import HandlerLineCollection, HandlerTuple\n",
    "import numpy as np\n",
    "import pydotplus\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz # Import Decision Tree Classifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score,\\\n",
    "        roc_auc_score, auc, precision_recall_curve, roc_curve, log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from IPython.display import Image \n",
    "\n",
    "import random\n",
    "## set seed for randomization\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e86997-9dc3-445f-ab37-f0401e0070e9",
   "metadata": {},
   "source": [
    "## Handling the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9fd6b1",
   "metadata": {},
   "source": [
    "### Pima Indians Diabetes dataset\n",
    "We will use the Pima Indians dataset to experiment with decision trees. The Pima are a group of Native Americans living in Arizona. A genetic predisposition allowed this group to survive normally to a diet poor of carbohydrates for years. In the recent years, because of a sudden shift from traditional agricultural crops to processed foods, together with a decline in physical activity, made them develop the highest prevalence of type 2 diabetes and for this reason they have been subject of many studies. \n",
    "\n",
    "The dataset can be downloaded [here](https://www.kaggle.com/uciml/pima-indians-diabetes-database#diabetes.csv), but I have already downloaded a local copy named `diabetes.csv`.\n",
    "\n",
    "The dataset includes data from 768 women. The columns are defined as follows:\n",
    "\n",
    "* `Pregnancies`: Number of times pregnant\n",
    "* `Glucose`: Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "* `BloodPressure`: Diastolic blood pressure (mm Hg)\n",
    "* `SkinThickness`: Triceps skin fold thickness (mm)\n",
    "* `Insulin`: 2-Hour serum insulin (mu U/ml)\n",
    "* `BMI`: Body mass index (weight in kg/(height in m)^2)\n",
    "* `DiabetesPedigreeFunction`: The output of the pedigree function that provides measure of genetic influence and gives us an idea of the hereditary risk one might have with the onset of diabetes mellitus\n",
    "* `Age`: Age (years)\n",
    "* `Outcome`: Class variable (0 or 1) 268 of 768 are 1 (positive), the others are 0 (negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e78666b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load Pima Indians Diabetes dataset (downloaded May 14, 2019; N=768)\n",
    "df = pd.read_csv(\"diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14289dd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30139381-f0cc-48e1-8767-b07b38ed64d2",
   "metadata": {},
   "source": [
    "### Missingness\n",
    "\n",
    "The only cleaning we need to do is to drop the rows that contain missing values. In general practice, you do not remove these rows without further exploratory analysis. However, for sake of this example, we have omitted rows that contain missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c0fa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to determine of a row has an missing value\n",
    "def valid_value(row):\n",
    "    if 0 == row['Glucose'] or \\\n",
    "       0 == row['BloodPressure'] or \\\n",
    "       0 == row['SkinThickness'] or \\\n",
    "       0 == row['Insulin'] or \\\n",
    "       0 == row['BMI'] or \\\n",
    "       0 == row['Age']:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "## create dataframe with only valid rows\n",
    "df_pima = df[df.apply(lambda row: valid_value(row), axis=1)]\n",
    "df_pima.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e915e061",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total number of samples in dataset = {len(df_pima)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa808fa",
   "metadata": {},
   "source": [
    "### Training/testing split\n",
    "\n",
    "Now we split the data into our training and test sets. We do this because we need to train the model on some of the data and ensure that we have generalizable model by testing the optimized model on samples it has never seen.\n",
    "\n",
    "<p style=\"text-align: center;\">\n",
    "  <img width=\"700px\" src=\"img/train_test_split-procedure.jpg\">\n",
    "  <em><small>Image taken from <a href=\"https://www.machinelearningplus.com/machine-learning/train-test-split/\">Train Test Split - How to split data into train and test for validating machine learning models?</a></small></em>\n",
    "</p>\n",
    "\n",
    "First, we separate the features. By convention, scikit-learn often refers to the feature dataset as `X` and the target dataset as `y`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7397e5b",
   "metadata": {},
   "source": [
    "In order to build the decision tree, we will need to split the dataset into a training set and a test set. The training set that is used to build the tree, and the test set that is used to evaluate it.\n",
    "\n",
    "This is necessary for both the feature dataset (`X`) and the target/outcome dataset (`y`).\n",
    "\n",
    "Scikit-learn's `train_test_split()` funciton allows us to easily do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff22bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## split dataset in features and target variable\n",
    "feature_cols = \\\n",
    "    ['Pregnancies', 'Insulin', 'BMI', 'Age','Glucose',\n",
    "     'BloodPressure','DiabetesPedigreeFunction', 'SkinThickness']\n",
    "\n",
    "X = df_pima[feature_cols]\n",
    "y = df_pima['Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b749d142",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=0.2, random_state=42) # 80% training and 20% test\n",
    "print(f\"Number of samples in trianing set = {len(X_train)}\")\n",
    "print(f\"Number of samples in testing set = {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b9f351",
   "metadata": {},
   "source": [
    "### Stratified sampling\n",
    "\n",
    "Above we randomly sampled from the overall dataset to get our training and testing data split. However, we know our dataset is imbalanced (far fewer positive samples than negative samples). When we randomly sample, we may be getting a different ratio of positive to negative class in each dataset. \n",
    "\n",
    "Let's see what the ratios look like from our previous splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55f51da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"Number of positive samples in training set = {y_train.to_list().count(1)}\")\n",
    "print(f\"Number of negative samples in training set = {y_train.to_list().count(0)}\")\n",
    "print(f\"Ratio of positive to negative samples in training set = {y_train.to_list().count(1)/y_train.to_list().count(0):.3f}\\n\")\n",
    "\n",
    "print(f\"Number of positive samples in testing set = {y_test.to_list().count(1)}\")\n",
    "print(f\"Number of negative samples in testing set = {y_test.to_list().count(0)}\")\n",
    "print(f\"Ratio of positive to negative samples in testing set = {y_test.to_list().count(1)/y_test.to_list().count(0):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75914d1",
   "metadata": {},
   "source": [
    "As you can see, the ratio is not the same between the training and testing sets. We need to make these ratios closer. We can do this by stratifying our sampling technique to specifically select the same number of samples based on a given variables/feature. In our case, we want to stratify by the outcome variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84509ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=0.2, random_state=42, stratify=df_pima['Outcome']) # 80% training and 20% test\n",
    "print(f\"Number of samples in trianing set = {len(X_train)}\")\n",
    "print(f\"Number of samples in testing set = {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bcce3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"Number of positive samples in training set = {y_train.to_list().count(1)}\")\n",
    "print(f\"Number of negative samples in training set = {y_train.to_list().count(0)}\")\n",
    "print(f\"Ratio of positive to negative samples in training set = {y_train.to_list().count(1)/y_train.to_list().count(0):.3f}\\n\")\n",
    "\n",
    "print(f\"Number of positive samples in testing set = {y_test.to_list().count(1)}\")\n",
    "print(f\"Number of negative samples in testing set = {y_test.to_list().count(0)}\")\n",
    "print(f\"Ratio of positive to negative samples in testing set = {y_test.to_list().count(1)/y_test.to_list().count(0):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c94d506",
   "metadata": {},
   "source": [
    "Now our ratios of positive to negative is the same for both sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1fe46b",
   "metadata": {},
   "source": [
    "## Implementing decision trees\n",
    "Now that the data has been inspected and cleaned, we can implement a decision tree.\n",
    "\n",
    "For this will will use scikit-learn's `DecisionTreeClassifier()`:\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1146b7",
   "metadata": {},
   "source": [
    "The hierarchical structure of a decision tree leads us to the final outcome by traversing through the nodes of the tree. Each node consists of an attribute or feature which is further split into more nodes as we move down the tree.\n",
    "\n",
    "The Gini index (or Gini impurity) is the default method used determine the features to used at each node. Briefly, Gini index measures the degree or probability of a particular sample being wrongly classified when it is randomly chosen. \n",
    "\n",
    "$Gini = \\sum p_i * (1 - p_i)$\n",
    "\n",
    "If all the elements belong to a single class, then it can be called pure. The degree of Gini index varies between 0 and 1, where 0 denotes that all elements belong to a certain class or if there exists only one class, and 1 denotes that the elements are randomly distributed across various classes. A Gini Index of 0.5 denotes equally distributed elements into some classes.\n",
    "\n",
    "*The goal is to have the lowest possible Gini index at each split.*\n",
    "\n",
    "Let's calculate the gini index in the following example:\n",
    "\n",
    "<p style=\"text-align: center;\">\n",
    "  <img width=\"600px\" src=\"img/gini_example.png\">\n",
    "  <em><small>Image taken from <a href=\"https://keytodatascience.com/decision-tree/\">Decision Tree</a></small></em>\n",
    "</p>\n",
    "\n",
    "The variable and threhold chosen for the root node is delivery time <= 27.5. According to the data in the root node, there are 5 total samples with 2 being in the negative class (No) and 3 being in the positive class (Yes). According to the subsequent decision nodes, the split from the root node is 4 on the left and 1 on the right. Furthermore, the left has 1 No and 3 Yes samples while the right has 1 No and 0 Yes samples.\n",
    "\n",
    "Using this information, let's calculate the gini index for each of these nodes. The gini index for the whole dataset is simply based on the total samples, in which case we have 2 No and 3 Yes samples.\n",
    "\n",
    "$Gini_{dataset} = \\frac{2}{5} * (1 - \\frac{2}{5}) +  \\frac{3}{5} * (1 - \\frac{3}{5}) = 0.48$\n",
    "\n",
    "Which lines up with the value printed in the root node. Now let's calculate for the left node where we have 1 No and 3 Yes samples...\n",
    "\n",
    "$Gini_{left} = \\frac{1}{4} * (1 - \\frac{1}{4}) + \\frac{3}{4} * (1 - \\frac{3}{4}) = 0.375$\n",
    "\n",
    "And lastly, we will calculate for the right with 1 No and 0 Yes samples...\n",
    "\n",
    "$Gini_{right} = \\frac{1}{1} * (1 - \\frac{1}{1}) + \\frac{0}{1} * (1 - \\frac{0}{1}) = 0.0$\n",
    "\n",
    "Now this is good and it all aligns with what is in the printed nodes, however there is a final step to calculate the gini gain which is then used to determine which variable/threshold is used at the root node (or any decision node). The final calculation involves first taking the weighted gini index for each node (branch) following the decision node (root node in our case). \n",
    "\n",
    "$Gini_{root} = \\frac{4}{5} * 0.375 + \\frac{1}{5} * 0.0 = 0.30$\n",
    "\n",
    "Then the gini index for the node is subtracted from the starting gini index\n",
    "\n",
    "$Gain = 0.48 - 0.30 = 0.18$\n",
    "\n",
    "The higher the Gini gain equates to a higher amount of \"impurity\" removed wtih the corresponding split. This is does iteratively over a given set of split criteria (variables/thresholds) and the one that results in the highest Gini gain is selected. In this case, delivery time <= 27.5 had the highest Gini gain.\n",
    "\n",
    "More information about the Gini index and other methods for feature splitting is found here:\n",
    "* https://blog.quantinsti.com/gini-index/\n",
    "* https://medium.com/deep-math-machine-learning-ai/chapter-4-decision-trees-algorithms-b93975f7a1f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4642afa4",
   "metadata": {},
   "source": [
    "In the below code, we create a decision tree named `dtree`. After the tree is created, the `fit` method is called to train (i.e., build) the tree using the training data `X_train` and `y_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7962e273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create decision tree classifer object\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "# train decision tree classifer\n",
    "dtree = dtree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f54b55c",
   "metadata": {},
   "source": [
    "Let's look at some attributes of the trained model to get an idea of the general shape of the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca3f157",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Depth of tree = {dtree.get_depth()}\")\n",
    "print(f\"Number of leaves = {dtree.get_n_leaves()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b333b09",
   "metadata": {},
   "source": [
    "## Visualizing the tree\n",
    "With the decision tree built, we can visualize the nodes. For this will use scikit-learn's `export_graphviz()` funciton:\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\n",
    "\n",
    "The generated figure is difficult read, but if you **squint** you may be able to make out the features and values used to make the splits. Importantly, the Gini index of all leaf nodes is `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9625619",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from six import StringIO \n",
    "from IPython.display import Image, display\n",
    "\n",
    "# export the tree as dot\n",
    "dot_data = tree.export_graphviz(dtree, out_file=None, filled=True, \n",
    "                                feature_names=feature_cols, \n",
    "                                class_names=['neg','pos'])\n",
    "# Draw graph\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)  \n",
    "\n",
    "# Show graph\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebec401",
   "metadata": {},
   "source": [
    "## Tree pruning\n",
    "A disadvantage of decision trees is that they are prone to overfitting as they grow larger and more complex. In order to avoid or correct overfitting we can **prune** the tree. One way to do this is by limiting the maximum depth of the tree. Another way is use cost complexity pruning. The former just limits the length of the longest path of the decision tree, which will stop the tree from becoming too complex and overfitting the data. Cost complexity pruning places a penalty on the number of terminal leaves that exist in the model, thus restricting the complexity of the tree. The higher the cost complexity value (alpha) the simpler the subtree will be. These pruning methods may increase training error, but the resulting model will be far more robust to your testing data, i.e. decrease variance as the cost of increased bias.\n",
    "\n",
    "<p style=\"text-align: center;\">\n",
    "  <img width=\"800px\" src=\"img/before_after_prune.png\">\n",
    "  <em><small>Image taken from <a href=\"https://github.com/jameschanx/Decision_Tree_Post_Pruner-Scikit_Extension?tab=readme-ov-file\">Decision Tree Post Pruner (Sci-kit Learn Extension)</a></small></em>\n",
    "</p>\n",
    "\n",
    "These *pruning* options are considered **hyperparameters**. Hyperparameters are parameters set prior to the model being trained and modulate how the model is trained and therefore directly influence the resulting parameters (weights) in the model.\n",
    "\n",
    "Below I define a decision tree with a maximum depth of `4` and a decision tree with a cost complexity pruning value of `0.01`, and for convenience I use the labels `neg` and `pos` instead of `0` and `1`. \n",
    "\n",
    "It also makes the tree much easier to read :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e82f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prune the tree to a max depth of 4\n",
    "dtree_shallow = DecisionTreeClassifier(max_depth=4)\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "dtree_shallow = dtree_shallow.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d613e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"shallow\")\n",
    "print(f\"Depth of tree = {dtree_shallow.get_depth()}\")\n",
    "print(f\"Number of leaves = {dtree_shallow.get_n_leaves()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74ccf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## visualize the pruned tree\n",
    "dot_data = \\\n",
    "    tree.export_graphviz(dtree_shallow, out_file=None, filled=True, \n",
    "                         feature_names=feature_cols, \n",
    "                         class_names=['neg','pos'])\n",
    "\n",
    "# Draw graph\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)  \n",
    "\n",
    "# Show graph\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cda69b9",
   "metadata": {},
   "source": [
    "And now to run the \"pruned\" tree..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ee45dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prune the tree to using a complexity parameter of 0.01\n",
    "dtree_pruned = DecisionTreeClassifier(ccp_alpha=0.01) # default criterion=\"gini\"\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "dtree_pruned = dtree_pruned.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deac750d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"pruned\")\n",
    "print(f\"Depth of tree = {dtree_pruned.get_depth()}\")\n",
    "print(f\"Number of leaves = {dtree_pruned.get_n_leaves()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b106216",
   "metadata": {},
   "outputs": [],
   "source": [
    "## visualize the pruned tree\n",
    "dot_data = \\\n",
    "    tree.export_graphviz(dtree_pruned, out_file=None, filled=True, \n",
    "                         feature_names=feature_cols, \n",
    "                         class_names=['neg','pos'])\n",
    "\n",
    "# Draw graph\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)  \n",
    "\n",
    "# Show graph\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40286e7",
   "metadata": {},
   "source": [
    "## Evaluating the model\n",
    "We need to now evaluate the decision trees (pruned and full). For this, we will use the decision tree `predict()` method. The output of this method will be stored in the variables `y_pred_tree`, `y_pred_shallow`, and `y_pred_pruned`. These (predicted) variables will assedd using a confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1469e396-f353-42fe-8b12-9a6ba8c5bbd3",
   "metadata": {},
   "source": [
    "### Confusion matrix\n",
    "<img width=\"600px\" src=\"img/confusion_matrix5.png\" />\n",
    "\n",
    "A confusion matrix is a summary of prediction results on a classification problem.\n",
    "The number of correct and incorrect predictions are summarized with count values and broken down by each class. This is the key to the confusion matrix.\n",
    "The confusion matrix shows the ways in which your classification model is confused when it makes predictions.\n",
    "It gives us insight not only into the errors being made by a classifier but more importantly the types of errors that are being made.\n",
    "\n",
    "**Definition of the Terms**:\n",
    "* Positive (P) : Observation is positive (for example: is an apple).\n",
    "* Negative (N) : Observation is not positive (for example: is not an apple).\n",
    "* True Positive (TP) : Observation is positive, and is predicted to be positive.\n",
    "* False Negative (FN) : Observation is positive, but is predicted negative.\n",
    "* True Negative (TN) : Observation is negative, and is predicted to be negative.\n",
    "* False Positive (FP) : Observation is negative, but is predicted positive.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fb1d00-2e13-4273-ba7c-31608c53a031",
   "metadata": {},
   "source": [
    "### Typical performance metrics\n",
    "Using the confusion matrix, we can define the following metrics of evaluation.\n",
    "\n",
    "**Accuracy:**\n",
    "* $\\frac{TP + TN}{TP + TN + FP + FN}$\n",
    "* Accuracy is the ratio of correct predictions to total predictions made. However, there are problems with accuracy. It assumes equal costs for both kinds of errors. A 99% accuracy can be excellent, good, mediocre, poor or terrible depending upon the problem.\n",
    "\n",
    "**Precision:**\n",
    "* $\\frac{TP}{TP + FP}$\n",
    "* Precision is the ability of a classifier not to label an instance positive that is actually negative. \n",
    "* High precision indicates a small number of false positives.\n",
    "\n",
    "**Recall:**\n",
    "* $\\frac{TP}{TP + FN}$\n",
    "* Recall is the ability of a classifier to find all positive instances. \n",
    "* High recall indicates a small number of false negatives.\n",
    "\n",
    "**F1 score (F measure):**\n",
    "* $\\frac{2 * Recall * Precision}{Recall + Precision}$\n",
    "* Since we have two measures (Precision and Recall) it helps to have a measurement that represents both of them. We calculate an F1 score that uses Harmonic Mean in place of Arithmetic Mean as it punishes the extreme values more. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fb5fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predict the response for dtree, dtree_shallow, and dtree_pruned decision trees\n",
    "y_pred_tree = dtree.predict(X_test)\n",
    "y_pred_shallow = dtree_shallow.predict(X_test)\n",
    "y_pred_pruned = dtree_pruned.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12ba6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get values for confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_tree).ravel()\n",
    "print(f\"True Negative = {tn}\\nFalse Positive = {fp}\\nFalse Negative = {fn}\\nTrue Positive = {tp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac844033",
   "metadata": {},
   "source": [
    "If we wish, we can also visualize the confusion matrix of the trees. For convenience, I will define a function to do this. This will allow us to more easily visualize the confusion matrix later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abcb466",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_confusion_matrix(y_test, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    colors = sns.color_palette(\"Blues\")\n",
    "    ax = sns.heatmap([[tp,fp],[fn,tn]], square=True, annot=True, fmt='d', \n",
    "                     cbar=False, cmap=colors, vmin=-1, annot_kws={\"size\":13}, linewidths=1.0)\n",
    "    # set labels on figure\n",
    "    ax.set_xticklabels(labels=[\"pos\",\"neg\"], fontsize=13)\n",
    "    ax.xaxis.tick_top()\n",
    "    ax.set_yticklabels(labels=[\"pos\",\"neg\"], fontsize= 13)\n",
    "    plt.xlabel(\"\\nactual value\", fontsize=15)\n",
    "    ax.xaxis.set_label_position('top') \n",
    "    plt.ylabel(\"predicted value\\n\", fontsize=15)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b262a6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## show confusion matrix for dtree\n",
    "print(\"tree\")\n",
    "show_confusion_matrix(y_test, y_pred_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb7bf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "## show confusion matrix for dtree_shallow\n",
    "print(\"shallow\")\n",
    "show_confusion_matrix(y_test, y_pred_shallow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d3eb54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## show confusion matrix for dtree_pruned\n",
    "print(\"pruned\")\n",
    "show_confusion_matrix(y_test, y_pred_pruned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f4ca5b",
   "metadata": {},
   "source": [
    "Sci-kit learn also provides `accuracy_score`, `recall_score`, `precision_score`, and `f1_score` functions to make these calculations easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b36da4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy\")\n",
    "print(f\"tree: {accuracy_score(y_test, y_pred_tree):.3f}\")\n",
    "print(f\"shallow: {accuracy_score(y_test, y_pred_shallow):.3f}\")\n",
    "print(f\"pruned: {accuracy_score(y_test, y_pred_pruned):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec31c2fd",
   "metadata": {},
   "source": [
    "Here are the recall and precision scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a595c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Recall\")\n",
    "print(f\"tree: {recall_score(y_test, y_pred_tree):.3f}\")\n",
    "print(f\"shallow: {recall_score(y_test, y_pred_shallow):.3f}\")\n",
    "print(f\"pruned: {recall_score(y_test, y_pred_pruned):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2418d8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Precision\")\n",
    "print(f\"tree: {precision_score(y_test, y_pred_tree):.3f}\")\n",
    "print(f\"shallow: {precision_score(y_test, y_pred_shallow):.3f}\")\n",
    "print(f\"pruned: {precision_score(y_test, y_pred_pruned):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194b53b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F1 score\")\n",
    "print(f\"tree: {f1_score(y_test, y_pred_tree):.3f}\")\n",
    "print(f\"shallow: {f1_score(y_test, y_pred_shallow):.3f}\")\n",
    "print(f\"pruned: {f1_score(y_test, y_pred_pruned):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ceee26c",
   "metadata": {},
   "source": [
    "Notice that the accuracy and precision scores in the pruned and full trees are close. However the recall score is better in the pruned tree, meaning that the pruned tree has a smaller number of false negatives. Compare the lower left boxes in the two confusion matrices below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183891aa",
   "metadata": {},
   "source": [
    "### Receiver operating characteristic curve\n",
    "\n",
    "Another common metric for classification problems is area under the receiver operating characteristic (ROC) curve. This plot, and associated scalar metric, assesses a model's performance by comparing the true positive rate (TPR) to the false positive rate (FPR) at varying thresholds. What this means is as the threshold varies from 0 to 1, can the model still successfully discern the two classes.\n",
    "\n",
    "**Sensitivity/Recall/True positive rate (TPR):**\n",
    "* TPR = TP / (TP + FN)\n",
    "* TPR is the ability of a classifier to find all positive instances. \n",
    "* High TPR indicates a small number of false negatives.\n",
    "\n",
    "**Specificity/True negative rate (TNR):**\n",
    "* TNR = TN / (TN + FP)\n",
    "* TNR is the ability of a classifier to find all negative instances. \n",
    "* High TNR indicates a small number of false positives.\n",
    "\n",
    "**False positive rate (FPR):**\n",
    "* FPR = FP / (FP + TN)\n",
    "* FPR is the ability of a classifier to incorrectly predict positives instances. \n",
    "* Low FPR indications a small number of false positives.\n",
    "\n",
    "<img width=\"300px\" src=\"img/sensitivity-specificity.png\" />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60110870",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr, tpr):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.fill_between(fpr, tpr, alpha=.5, color='darkorange')\n",
    "    ax.plot(fpr, tpr, color='darkorange', lw=2, label=f'AUROC = {auc(fpr,tpr):.3f}')\n",
    "    # Add dashed line with a slope of 1\n",
    "    ax.plot([0,1], [0,1], color='black', linestyle='dotted', lw=2, \\\n",
    "            label=f'Random = 0.500')\n",
    "    ax.legend()\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac53cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predict the response for dtree, dtree_shallow, and dtree_pruned decision trees\n",
    "y_proba_tree = list(zip(*dtree.predict_proba(X_test)))[1]\n",
    "y_proba_shallow = list(zip(*dtree_shallow.predict_proba(X_test)))[1]\n",
    "y_proba_pruned = list(zip(*dtree_pruned.predict_proba(X_test)))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ed9a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_tree, tpr_tree, thresholds_tree = roc_curve(y_test, y_proba_tree)\n",
    "fpr_shallow, tpr_shallow, thresholds_shallow = roc_curve(y_test, y_proba_shallow)\n",
    "fpr_pruned, tpr_pruned, thresholds_pruned = roc_curve(y_test, y_proba_pruned)\n",
    "\n",
    "print(\"AUROC\")\n",
    "print(f\"tree: {auc(fpr_tree,tpr_tree):.3f}\")\n",
    "print(f\"shallow: {auc(fpr_shallow,tpr_shallow):.3f}\")\n",
    "print(f\"pruned: {auc(fpr_pruned,tpr_pruned):.3f}\")\n",
    "print(f\"Random (no skill) AUROC: {auc([0,1], [0,1]):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60ac902",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"tree\")\n",
    "plot_roc_curve(fpr_tree,tpr_tree)\n",
    "print(\"shallow\")\n",
    "plot_roc_curve(fpr_shallow,tpr_shallow)\n",
    "print(\"pruned\")\n",
    "plot_roc_curve(fpr_pruned,tpr_pruned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cdc83d",
   "metadata": {},
   "source": [
    "### Precision recall curve\n",
    "\n",
    "Related to the above ROC curve, the precision recall curve, and the area under it, is often used as a metric to determine classification model efficacy. \n",
    "\n",
    "\n",
    "<img width=\"300px\" src=\"img/precision-recall.png\" />\n",
    "\n",
    "This metric is especially important for imbalanced class sizes -- one class has far more samples (majority) than the other class (minority). The difference between this curve and the ROC curve is the use of precision instead of FPR (TPR and recall are the same metric). Precision is less affected by a large number of negative samples because it takes into account true positives and false positives. On the other hand, FPR is based upon false positives and true negatives so for a large number of negative samples this metric would very slowly increase. **Precision is focused on the positive class**\n",
    "\n",
    "*Use AUPR when you have imbalanced classes, specifically when you have a majority of negative samples (usually the case).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04524555",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pr_curve(recall, precision, random_aupr):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.fill_between(recall, precision, alpha=.5, color='blue')\n",
    "    ax.plot(recall, precision, color='blue', lw=2, label=f'AUPR = {auc(recall, precision):.3f}')\n",
    "    # Add dashed line where random (or no skill) would be\n",
    "    ax.plot([1,0], [random_aupr,random_aupr], color='black', linestyle='dotted', \\\n",
    "            lw=2, label=f'Random = {random_aupr:.3f}')\n",
    "    ax.legend()\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a8c2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_tree, recall_tree, thresholds_tree = precision_recall_curve(y_test, y_proba_tree)\n",
    "precision_shallow, recall_shallow, thresholds_shallow = precision_recall_curve(y_test, y_proba_shallow)\n",
    "precision_pruned, recall_pruned, thresholds_pruned = precision_recall_curve(y_test, y_proba_pruned)\n",
    "\n",
    "print(\"AUPR\")\n",
    "print(f\"tree: {auc(recall_tree, precision_tree):.3f}\")\n",
    "print(f\"shallow: {auc(recall_shallow, precision_shallow):.3f}\")\n",
    "print(f\"pruned: {auc(recall_pruned, precision_pruned):.3f}\")\n",
    "\n",
    "positive_class = y_test.to_list().count(1)\n",
    "negative_class = y_test.to_list().count(0)\n",
    "random_control = positive_class/(positive_class+negative_class)\n",
    "\n",
    "print(f\"Random (no skill) AUPR = {auc([0,1], [random_control,random_control]):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bae40f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"tree\")\n",
    "plot_pr_curve(recall_tree,precision_tree,random_control)\n",
    "print(\"shallow\")\n",
    "plot_pr_curve(recall_shallow,precision_shallow,random_control)\n",
    "print(\"pruned\")\n",
    "plot_pr_curve(recall_pruned,precision_pruned,random_control)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527e413d",
   "metadata": {},
   "source": [
    "## Bias-variance tradeoff\n",
    "\n",
    "**Variance** is the error in the model due to sensitivity to the data. \n",
    "\n",
    "High variance means our model is *overfit* and has been trained to the noise in the data.\n",
    "\n",
    "**Bias** is the error between the predicted and known labels for our data.\n",
    "\n",
    "High bias means our model is *underfit* and does not predict the correct outcome for our data.\n",
    "\n",
    "<img width=\"400px\" src=\"img/hl_bias-hl_variance.png\" /> \n",
    "\n",
    "We can think about (A) high variance and high bias, (B) low variance and high bias, (C) high variance and low bias, and (D) low variance and low bias. We are aiming to accomplish (D)!\n",
    "\n",
    "So, when we look at the plot below we can relate variance and bias directly to how we are training our models. We are looking to hit that sweet spot where the bias and variance curves intersect. That is a good model.\n",
    "\n",
    "<img width=\"400px\" src=\"img/variance_v_bias.jpeg\" /> \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
